{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8f1208d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /home/codespace/anaconda3/lib/python3.9/site-packages (16.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/codespace/anaconda3/lib/python3.9/site-packages (from pyarrow) (1.21.5)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad57d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data file form here: https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d9c957",
   "metadata": {},
   "source": [
    "## libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd8c402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a5a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f856e9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9bb9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9a18a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd83a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in January data: 19\n",
      "Standard deviation of trip duration in January: 131.20\n",
      "Fraction of records remaining after filtering outliers: 98.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27785/3009794097.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.loc[:, columns] = df[columns].astype(str)  # Use .loc to avoid SettingWithCopyWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality of the feature matrix: 518\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def download_data(url, filename):\n",
    "    df = pd.read_parquet(url)\n",
    "    df.to_parquet(filename)\n",
    "    return df\n",
    "\n",
    "def load_data(filename):\n",
    "    return pd.read_parquet(filename)\n",
    "\n",
    "def compute_duration(df):\n",
    "    df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "    df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "    df['duration'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "    return df\n",
    "\n",
    "def filter_outliers(df, min_duration=1, max_duration=60):\n",
    "    return df[(df['duration'] >= min_duration) & (df['duration'] <= max_duration)]\n",
    "\n",
    "def one_hot_encode(df, columns):\n",
    "    df.loc[:, columns] = df[columns].astype(str)  # Use .loc to avoid SettingWithCopyWarning\n",
    "    data_dicts = df[columns].to_dict(orient='records')\n",
    "    dv = DictVectorizer()\n",
    "    X = dv.fit_transform(data_dicts)\n",
    "    return X, dv\n",
    "\n",
    "def train_model(X, y):\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    return model\n",
    "\n",
    "def calculate_rmse(model, X, y):\n",
    "    y_pred = model.predict(X)\n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    return rmse\n",
    "\n",
    "def main():\n",
    "    # URLs for the datasets\n",
    "    url_january = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-01.parquet\"\n",
    "    url_february = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2021-02.parquet\"\n",
    "\n",
    "    # Filenames for local storage\n",
    "    filename_january = \"yellow_tripdata_2021-01.parquet\"\n",
    "    filename_february = \"yellow_tripdata_2021-02.parquet\"\n",
    "\n",
    "    # Download and load the data\n",
    "    df_january = download_data(url_january, filename_january)\n",
    "    df_february = download_data(url_february, filename_february)\n",
    "\n",
    "    # Question 1\n",
    "    num_columns_january = df_january.shape[1]\n",
    "    print(f\"Number of columns in January data: {num_columns_january}\")\n",
    "\n",
    "    # Question 2\n",
    "    df_january = compute_duration(df_january)\n",
    "    std_duration = df_january['duration'].std()\n",
    "    print(f\"Standard deviation of trip duration in January: {std_duration:.2f}\")\n",
    "\n",
    "    # Question 3\n",
    "    df_january_filtered = filter_outliers(df_january)\n",
    "    fraction_remaining = len(df_january_filtered) / len(df_january)\n",
    "    print(f\"Fraction of records remaining after filtering outliers: {fraction_remaining:.2%}\")\n",
    "\n",
    "    # Question 4\n",
    "    columns_to_encode = ['PULocationID', 'DOLocationID']\n",
    "    X_january, dv = one_hot_encode(df_january_filtered, columns_to_encode)\n",
    "    dimensionality = X_january.shape[1]\n",
    "    print(f\"Dimensionality of the feature matrix: {dimensionality}\")\n",
    "\n",
    "    # Question 5\n",
    "    y_january = df_january_filtered['duration'].values\n",
    "    model = train_model(X_january, y_january)\n",
    "    rmse_train = calculate_rmse(model, X_january, y_january)\n",
    "    print(f\"RMSE on training data: {rmse_train:.2f}\")\n",
    "\n",
    "    # Question 6\n",
    "    df_february = compute_duration(df_february)\n",
    "    df_february_filtered = filter_outliers(df_february)\n",
    "    X_february = dv.transform(df_february_filtered[columns_to_encode].to_dict(orient='records'))\n",
    "    y_february = df_february_filtered['duration'].values\n",
    "    rmse_val = calculate_rmse(model, X_february, y_february)\n",
    "    print(f\"RMSE on validation data: {rmse_val:.2f}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print(f\"Notebook duration: {duration:.2f} seconds\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bcfd3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
